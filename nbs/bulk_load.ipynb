{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e85ed483-d2ef-4920-a1b5-51dd0eddf4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0pEnqPfhRk7bYu5LSa7ppMuKfqr21kck\n"
     ]
    }
   ],
   "source": [
    "import setup\n",
    "setup.init_django()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da110c89-fc4d-4751-840b-2a95891c50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers.clients as helper_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15cec661-367b-45d0-a99d-919aaf786956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee0918d4-50a3-41f2-b00c-2c125ddeeeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# # Configuration\n",
    "# company_name = \"NVDA\"\n",
    "# company_ticker = \"NVDA\"\n",
    "# multiplier = 1\n",
    "# from_date = \"2025-01-01\"\n",
    "# to_date = \"2025-01-20\"\n",
    "# batch_size = 1000  # Batch size for database inserts\n",
    "# date_format = \"%Y-%m-%d\"\n",
    "\n",
    "# # Initialize API client\n",
    "# client = helper_clients.PolygonAPIClient(\n",
    "#     ticker=company_ticker,\n",
    "#     multiplier=multiplier,\n",
    "#     from_date=from_date,\n",
    "#     to_date=to_date\n",
    "# )\n",
    "# # Helper function to fetch data in date-range batches\n",
    "# def fetch_stock_data_in_batches(api_client, from_date, to_date, step_days=5):\n",
    "#     \"\"\"\n",
    "#     Fetches data in batches based on date ranges.\n",
    "\n",
    "#     :param api_client: Initialized API client\n",
    "#     :param from_date: Start date (string in 'YYYY-MM-DD')\n",
    "#     :param to_date: End date (string in 'YYYY-MM-DD')\n",
    "#     :param step_days: Number of days per batch\n",
    "#     :return: Consolidated dataset\n",
    "#     \"\"\"\n",
    "#     consolidated_data = []\n",
    "#     current_date = datetime.strptime(from_date, date_format)\n",
    "#     end_date = datetime.strptime(to_date, date_format)\n",
    "\n",
    "#     while current_date < end_date:\n",
    "#         batch_start = current_date.strftime(date_format)\n",
    "#         batch_end = (current_date + timedelta(days=step_days - 1)).strftime(date_format)\n",
    "\n",
    "#         if datetime.strptime(batch_end, date_format) > end_date:\n",
    "#             batch_end = to_date\n",
    "\n",
    "#         print(f\"Fetching data from {batch_start} to {batch_end}...\")\n",
    "#         api_client.from_date = batch_start\n",
    "#         api_client.to_date = batch_end\n",
    "\n",
    "#         batch_data = api_client.get_stock_data()\n",
    "#         consolidated_data.extend(batch_data)\n",
    "\n",
    "#         current_date += timedelta(days=step_days)\n",
    "\n",
    "#     return consolidated_data\n",
    "\n",
    "# def fetch_sma_data_in_batches(api_client, from_date, to_date, step_days=5):\n",
    "#     \"\"\"\n",
    "#     Fetches data in batches based on date ranges.\n",
    "\n",
    "#     :param api_client: Initialized API client\n",
    "#     :param from_date: Start date (string in 'YYYY-MM-DD')\n",
    "#     :param to_date: End date (string in 'YYYY-MM-DD')\n",
    "#     :param step_days: Number of days per batch\n",
    "#     :return: Consolidated dataset\n",
    "#     \"\"\"\n",
    "#     consolidated_data = []\n",
    "#     current_date = datetime.strptime(from_date, date_format)\n",
    "#     end_date = datetime.strptime(to_date, date_format)\n",
    "\n",
    "#     while current_date < end_date:\n",
    "#         batch_start = current_date.strftime(date_format)\n",
    "#         batch_end = (current_date + timedelta(days=step_days - 1)).strftime(date_format)\n",
    "\n",
    "#         if datetime.strptime(batch_end, date_format) > end_date:\n",
    "#             batch_end = to_date\n",
    "\n",
    "#         print(f\"Fetching data from {batch_start} to {batch_end}...\")\n",
    "#         api_client.from_date = batch_start\n",
    "#         api_client.to_date = batch_end\n",
    "\n",
    "#         batch_data = api_client.get_sma_data()\n",
    "#         consolidated_data.extend(batch_data)\n",
    "\n",
    "#         current_date += timedelta(days=step_days)\n",
    "\n",
    "#     return consolidated_data\n",
    "\n",
    "# def fetch_ema_data_in_batches(api_client, from_date, to_date, step_days=5):\n",
    "#     \"\"\"\n",
    "#     Fetches data in batches based on date ranges.\n",
    "\n",
    "#     :param api_client: Initialized API client\n",
    "#     :param from_date: Start date (string in 'YYYY-MM-DD')\n",
    "#     :param to_date: End date (string in 'YYYY-MM-DD')\n",
    "#     :param step_days: Number of days per batch\n",
    "#     :return: Consolidated dataset\n",
    "#     \"\"\"\n",
    "#     consolidated_data = []\n",
    "#     current_date = datetime.strptime(from_date, date_format)\n",
    "#     end_date = datetime.strptime(to_date, date_format)\n",
    "\n",
    "#     while current_date < end_date:\n",
    "#         batch_start = current_date.strftime(date_format)\n",
    "#         batch_end = (current_date + timedelta(days=step_days - 1)).strftime(date_format)\n",
    "\n",
    "#         if datetime.strptime(batch_end, date_format) > end_date:\n",
    "#             batch_end = to_date\n",
    "\n",
    "#         print(f\"Fetching data from {batch_start} to {batch_end}...\")\n",
    "#         api_client.from_date = batch_start\n",
    "#         api_client.to_date = batch_end\n",
    "\n",
    "#         batch_data = api_client.get_ema_data()\n",
    "#         consolidated_data.extend(batch_data)\n",
    "\n",
    "#         current_date += timedelta(days=step_days)\n",
    "\n",
    "#     return consolidated_data\n",
    "# def fetch_macd_data_in_batches(api_client, from_date, to_date, step_days=5):\n",
    "#     \"\"\"\n",
    "#     Fetches data in batches based on date ranges.\n",
    "\n",
    "#     :param api_client: Initialized API client\n",
    "#     :param from_date: Start date (string in 'YYYY-MM-DD')\n",
    "#     :param to_date: End date (string in 'YYYY-MM-DD')\n",
    "#     :param step_days: Number of days per batch\n",
    "#     :return: Consolidated dataset\n",
    "#     \"\"\"\n",
    "#     consolidated_data = []\n",
    "#     current_date = datetime.strptime(from_date, date_format)\n",
    "#     end_date = datetime.strptime(to_date, date_format)\n",
    "\n",
    "#     while current_date < end_date:\n",
    "#         batch_start = current_date.strftime(date_format)\n",
    "#         batch_end = (current_date + timedelta(days=step_days - 1)).strftime(date_format)\n",
    "\n",
    "#         if datetime.strptime(batch_end, date_format) > end_date:\n",
    "#             batch_end = to_date\n",
    "\n",
    "#         print(f\"Fetching data from {batch_start} to {batch_end}...\")\n",
    "#         api_client.from_date = batch_start\n",
    "#         api_client.to_date = batch_end\n",
    "\n",
    "#         batch_data = api_client.get_macd_data()\n",
    "#         consolidated_data.extend(batch_data)\n",
    "\n",
    "#         current_date += timedelta(days=step_days)\n",
    "\n",
    "#     return consolidated_data\n",
    "\n",
    "# def fetch_rsi_data_in_batches(api_client, from_date, to_date, step_days=5):\n",
    "#     \"\"\"\n",
    "#     Fetches data in batches based on date ranges.\n",
    "\n",
    "#     :param api_client: Initialized API client\n",
    "#     :param from_date: Start date (string in 'YYYY-MM-DD')\n",
    "#     :param to_date: End date (string in 'YYYY-MM-DD')\n",
    "#     :param step_days: Number of days per batch\n",
    "#     :return: Consolidated dataset\n",
    "#     \"\"\"\n",
    "#     consolidated_data = []\n",
    "#     current_date = datetime.strptime(from_date, date_format)\n",
    "#     end_date = datetime.strptime(to_date, date_format)\n",
    "\n",
    "#     while current_date < end_date:\n",
    "#         batch_start = current_date.strftime(date_format)\n",
    "#         batch_end = (current_date + timedelta(days=step_days - 1)).strftime(date_format)\n",
    "\n",
    "#         if datetime.strptime(batch_end, date_format) > end_date:\n",
    "#             batch_end = to_date\n",
    "\n",
    "#         print(f\"Fetching data from {batch_start} to {batch_end}...\")\n",
    "#         api_client.from_date = batch_start\n",
    "#         api_client.to_date = batch_end\n",
    "\n",
    "#         batch_data = api_client.get_rsi_data()\n",
    "#         consolidated_data.extend(batch_data)\n",
    "\n",
    "#         current_date += timedelta(days=step_days)\n",
    "\n",
    "#     return consolidated_data\n",
    "\n",
    "# # Fetch datasets in batches\n",
    "# print(\"Fetching datasets in batches...\")\n",
    "# stock_data = fetch_stock_data_in_batches(client, from_date, to_date)\n",
    "# sma_data = fetch_sma_data_in_batches(client, from_date, to_date)\n",
    "# ema_data = fetch_ema_data_in_batches(client, from_date, to_date)\n",
    "# macd_data = fetch_macd_data_in_batches(client, from_date, to_date)\n",
    "# rsi_data = fetch_rsi_data_in_batches(client, from_date, to_date)\n",
    "\n",
    "# print(f\"Stock Data Length: {len(stock_data)}\")\n",
    "# print(f\"SMA Data Length: {len(sma_data)}\")\n",
    "# print(f\"EMA Data Length: {len(ema_data)}\")\n",
    "# print(f\"MACD Data Length: {len(macd_data)}\")\n",
    "# print(f\"RSI Data Length: {len(rsi_data)}\")\n",
    "\n",
    "\n",
    "# print(f\"Stock Data Length: {len(stock_data)}\")\n",
    "# print(f\"SMA Data Length: {len(sma_data)}\")\n",
    "# print(f\"EMA Data Length: {len(ema_data)}\")\n",
    "# print(f\"MACD Data Length: {len(macd_data)}\")\n",
    "# print(f\"RSI Data Length: {len(rsi_data)}\")\n",
    "\n",
    "# print(sma_data[0])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22405efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching datasets in batches...\n",
      "Fetching data from 2025-01-01 to 2025-01-05...\n",
      "Fetching data from 2025-01-06 to 2025-01-10...\n",
      "Fetching data from 2025-01-11 to 2025-01-15...\n",
      "Fetching data from 2025-01-16 to 2025-01-20...\n",
      "Fetching data from 2025-01-01 to 2025-01-05...\n",
      "https://api.polygon.io/v1/indicators/sma/NVDA/?timestamp.gte=2025-01-01&timestamp.lte=2025-01-05&timespan=minute&adjusted=True&window=50&series_type=close&order=desc&limit=5000&apiKey=0pEnqPfhRk7bYu5LSa7ppMuKfqr21kck\n",
      "Fetching data from 2025-01-06 to 2025-01-10...\n",
      "https://api.polygon.io/v1/indicators/sma/NVDA/?timestamp.gte=2025-01-06&timestamp.lte=2025-01-10&timespan=minute&adjusted=True&window=50&series_type=close&order=desc&limit=5000&apiKey=0pEnqPfhRk7bYu5LSa7ppMuKfqr21kck\n",
      "Fetching data from 2025-01-11 to 2025-01-15...\n",
      "https://api.polygon.io/v1/indicators/sma/NVDA/?timestamp.gte=2025-01-11&timestamp.lte=2025-01-15&timespan=minute&adjusted=True&window=50&series_type=close&order=desc&limit=5000&apiKey=0pEnqPfhRk7bYu5LSa7ppMuKfqr21kck\n",
      "Fetching data from 2025-01-16 to 2025-01-20...\n",
      "https://api.polygon.io/v1/indicators/sma/NVDA/?timestamp.gte=2025-01-16&timestamp.lte=2025-01-20&timespan=minute&adjusted=True&window=50&series_type=close&order=desc&limit=5000&apiKey=0pEnqPfhRk7bYu5LSa7ppMuKfqr21kck\n",
      "Fetching data from 2025-01-01 to 2025-01-05...\n",
      "Fetching data from 2025-01-06 to 2025-01-10...\n",
      "Fetching data from 2025-01-11 to 2025-01-15...\n",
      "Fetching data from 2025-01-16 to 2025-01-20...\n",
      "Fetching data from 2025-01-01 to 2025-01-05...\n",
      "Fetching data from 2025-01-06 to 2025-01-10...\n",
      "Fetching data from 2025-01-11 to 2025-01-15...\n",
      "Fetching data from 2025-01-16 to 2025-01-20...\n",
      "Fetching data from 2025-01-01 to 2025-01-05...\n",
      "Fetching data from 2025-01-06 to 2025-01-10...\n",
      "Fetching data from 2025-01-11 to 2025-01-15...\n",
      "Fetching data from 2025-01-16 to 2025-01-20...\n",
      "Stock Data Length: 10545\n",
      "SMA Data Length: 11582\n",
      "EMA Data Length: 11582\n",
      "MACD Data Length: 11582\n",
      "RSI Data Length: 11582\n",
      "Stock Data Length: 10545\n",
      "SMA Data Length: 11582\n",
      "EMA Data Length: 11582\n",
      "MACD Data Length: 11582\n",
      "RSI Data Length: 11582\n",
      "{'value': 144.95196799999997, 'raw_timestamp': 1735952340000, 'time': datetime.datetime(2025, 1, 4, 0, 59, tzinfo=<UTC>)}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Configuration\n",
    "company_name = \"NVDA\"\n",
    "company_ticker = \"NVDA\"\n",
    "multiplier = 1\n",
    "from_date = \"2025-01-01\"\n",
    "to_date = \"2025-01-20\"\n",
    "batch_size = 1000  # Batch size for database inserts\n",
    "date_format = \"%Y-%m-%d\"\n",
    "\n",
    "# Initialize API client\n",
    "client = helper_clients.PolygonAPIClient(\n",
    "    ticker=company_ticker,\n",
    "    multiplier=multiplier,\n",
    "    from_date=from_date,\n",
    "    to_date=to_date\n",
    ")\n",
    "\n",
    "\n",
    "# Fetch datasets in batches\n",
    "print(\"Fetching datasets in batches...\")\n",
    "stock_data = client.fetch_stock_data_in_batches(from_date, to_date)\n",
    "sma_data = client.fetch_sma_data_in_batches(from_date, to_date)\n",
    "ema_data = client.fetch_ema_data_in_batches(from_date, to_date)\n",
    "macd_data = client.fetch_macd_data_in_batches(from_date, to_date)\n",
    "rsi_data = client.fetch_rsi_data_in_batches(from_date, to_date)\n",
    "\n",
    "print(f\"Stock Data Length: {len(stock_data)}\")\n",
    "print(f\"SMA Data Length: {len(sma_data)}\")\n",
    "print(f\"EMA Data Length: {len(ema_data)}\")\n",
    "print(f\"MACD Data Length: {len(macd_data)}\")\n",
    "print(f\"RSI Data Length: {len(rsi_data)}\")\n",
    "\n",
    "\n",
    "print(f\"Stock Data Length: {len(stock_data)}\")\n",
    "print(f\"SMA Data Length: {len(sma_data)}\")\n",
    "print(f\"EMA Data Length: {len(ema_data)}\")\n",
    "print(f\"MACD Data Length: {len(macd_data)}\")\n",
    "print(f\"RSI Data Length: {len(rsi_data)}\")\n",
    "\n",
    "print(sma_data[0])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ae82aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'open_price': 144.95, 'close_price': 144.99, 'high_price': 145, 'low_price': 144.95, 'number_of_trades': 405, 'volume': 35061, 'volume_weighted_average': 144.9929, 'raw_timestamp': 1735952340000, 'time': datetime.datetime(2025, 1, 4, 0, 59, tzinfo=<UTC>), 'sma_value': 144.95196799999997, 'ema_value': 144.95326007657056, 'macd_histogram': -0.003314802389779354, 'macd_signal': 0.0041518319275992985, 'macd_value': 0.0008370295378199444, 'rsi_value': 54.64643002711358}\n"
     ]
    }
   ],
   "source": [
    "# Merge additional datasets into the original dataset by matching raw_timestamp\n",
    "for item in stock_data:\n",
    "    matching_sma = next((c for c in sma_data if c['raw_timestamp'] == item['raw_timestamp']), None)\n",
    "    matching_ema = next((e for e in ema_data if e['raw_timestamp'] == item['raw_timestamp']), None)\n",
    "    matching_macd = next((m for m in macd_data if m['raw_timestamp'] == item['raw_timestamp']), None)\n",
    "    matching_rsi = next((r for r in rsi_data if r['raw_timestamp'] == item['raw_timestamp']), None)\n",
    "\n",
    "    # Add the values to the original dataset\n",
    "    item['sma_value'] = matching_sma['value'] if matching_sma else None\n",
    "    item['ema_value'] = matching_ema['value'] if matching_ema else None\n",
    "    if matching_macd:\n",
    "        item['macd_histogram'] = matching_macd.get('histogram')\n",
    "        item['macd_signal'] = matching_macd.get('signal')\n",
    "        item['macd_value'] = matching_macd.get('value')\n",
    "    item['rsi_value'] = matching_rsi['value'] if matching_rsi else None\n",
    "\n",
    "# Print the updated dataset for verification\n",
    "for item in stock_data:\n",
    "    print(item)\n",
    "    break  # Remove this break to print all items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b141e54a-9f1e-4538-b7d6-a4ad6d047066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from market.models import Company, StockQuote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "265e2daa-3a3a-4670-83eb-a0779a98ab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data in batches...\n",
      "Total Stock Quotes in Database: 10545\n"
     ]
    }
   ],
   "source": [
    "# company_obj, created = Company.objects.get_or_create(name=company_name, ticker=company_ticker)\n",
    "# company_obj, created = Company.objects.create(name=company_name, ticker=company_ticker)\n",
    "# company_obj, created = Company.objects.get(name=company_name, ticker=company_ticker)\n",
    "\n",
    "\n",
    "print(\"Saving data in batches...\")\n",
    "company_obj, _ = Company.objects.get_or_create(name=company_name, ticker=company_ticker)\n",
    "\n",
    "for i in range(0, len(stock_data), batch_size):\n",
    "    batch_chunk = stock_data[i:i + batch_size]\n",
    "    chunked_quotes = []\n",
    "    for data in batch_chunk:\n",
    "        chunked_quotes.append(StockQuote(company=company_obj, **data))\n",
    "    StockQuote.objects.bulk_create(chunked_quotes, ignore_conflicts=True)\n",
    "\n",
    "print(f\"Total Stock Quotes in Database: {StockQuote.objects.all().count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71687c75-33fd-4ad6-8e5e-11f71251745d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Company: Company object (12)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c781ee86-155e-4cb7-ab3c-383a7496e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_quotes = []\n",
    "# for data in dataset:\n",
    "#     new_quotes.append(\n",
    "#         StockQuote(company = company_obj, **data)\n",
    "#     )\n",
    "# StockQuote.objects.bulk_create(new_quotes, ignore_conflicts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee625d77-7adb-43db-a33c-1a9cfade4e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<QuerySet [<StockQuote: StockQuote object (832928)>, <StockQuote: StockQuote object (832929)>, <StockQuote: StockQuote object (832930)>, <StockQuote: StockQuote object (832931)>, <StockQuote: StockQuote object (832932)>, <StockQuote: StockQuote object (832933)>, <StockQuote: StockQuote object (832934)>, <StockQuote: StockQuote object (832935)>, <StockQuote: StockQuote object (832936)>, <StockQuote: StockQuote object (832937)>, <StockQuote: StockQuote object (832938)>, <StockQuote: StockQuote object (832939)>, <StockQuote: StockQuote object (832940)>, <StockQuote: StockQuote object (832941)>, <StockQuote: StockQuote object (832942)>, <StockQuote: StockQuote object (832943)>, <StockQuote: StockQuote object (832944)>, <StockQuote: StockQuote object (832945)>, <StockQuote: StockQuote object (832946)>, <StockQuote: StockQuote object (832947)>, '...(remaining elements truncated)...']>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StockQuote.objects.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e151fb7-4adc-4f0a-9108-37253ede501a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StockQuote object (832928)\n",
      "{'_state': <django.db.models.base.ModelState object at 0x1209946b0>, 'id': 832928, 'company_id': 12, 'open_price': Decimal('144.9500'), 'close_price': Decimal('144.9900'), 'high_price': Decimal('145.0000'), 'low_price': Decimal('144.9500'), 'number_of_trades': 405, 'volume': 35061, 'volume_weighted_average': Decimal('144.992900'), 'raw_timestamp': '1735952340000', 'time': datetime.datetime(2025, 1, 4, 0, 59, tzinfo=datetime.timezone.utc), 'sma_value': Decimal('144.9520'), 'ema_value': Decimal('144.9533'), 'macd_histogram': Decimal('-0.0033'), 'macd_signal': Decimal('0.0042'), 'macd_value': Decimal('0.0008'), 'rsi_value': Decimal('54.6464'), 'treasury_10y_yield': None, 'fed_funds_rate': None, 'cpi': None, 'ppi': None, 'u3': None, 'u6': None, 'gdp': None, 'cci': None, 'retail_sales': None, 'm2': None}\n"
     ]
    }
   ],
   "source": [
    "StockQuote.objects.all().count()\n",
    "print(StockQuote.objects.first())\n",
    "print(StockQuote.objects.first().__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e455533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
